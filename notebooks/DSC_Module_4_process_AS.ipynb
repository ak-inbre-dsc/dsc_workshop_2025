{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e60e30e-1a33-4082-bffa-7fdc956f06b1",
   "metadata": {},
   "source": [
    "# **Bioinformatics Pipeline Walkthrough**\n",
    "\n",
    "This document provides a step-by-step walkthrough of the adaptive sampling analysis pipeline. Each section includes an explanation and a corresponding bash code block that you can copy and run in your terminal. After many steps, there are \"Peek at the Output\" sections with commands to inspect the generated files.\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "* Ensure all necessary bioinformatics tools are installed (Minimap2, Samtools, Seqtk, Awk, Pigz, etc.).  \n",
    "* Your input data should be structured as expected by the script.  \n",
    "* You should be in the directory where you want the main output folder (Output\\_AS) to be created (e.g., ${HOME}).\n",
    "\n",
    "**Important:** Run these blocks sequentially in the **same terminal session**, as variables defined in earlier blocks are used in later ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c738921a-c03b-472b-a687-231d02d6f275",
   "metadata": {},
   "source": [
    "## **Section 0: Configuration & Initial Setup**\n",
    "\n",
    "This first block sets up crucial variables for the entire pipeline.\n",
    "\n",
    "* **SAMPLEID**: **You MUST modify this variable** to match the specific sample you are processing.  \n",
    "* **THREADS**: This is dynamically set to the number of available processing units on your system using nproc. You can optionally cap this.  \n",
    "* **BUCKET\\_DIR**: This points to the location of your input data. Adjust if your data is elsewhere. The script assumes a structure like ${BUCKET\\_DIR}/${SAMPLEID}/basecalled/....  \n",
    "* **REFERENCE\\_BASENAME**: The filename of your reference FASTA.  \n",
    "* **MAIN\\_OUTPUT\\_ROOT**: The root directory where all sample-specific output folders will be created.  \n",
    "* Other variables define names for intermediate files, lists for looping, and organism-specific reference names.\n",
    "\n",
    "**Copy and paste the entire block below into your terminal and press Enter.**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf026b48-23ef-4813-9d0f-4585110f8273",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "# Ensure this block is run in a fresh terminal session or after unsetting previous script variables.\n",
    "\n",
    "# --- Script Behavior ---\n",
    "set -e # Exit immediately if a command exits with a non-zero status.\n",
    "set -u # Treat unset variables as an error when substituting.\n",
    "set -o pipefail # Cause a pipeline to return the exit status of the last command in the pipe that failed.\n",
    "\n",
    "# --- 0. Configuration & User-Defined Variables ---\n",
    "echo \"--- Setting Up Configuration ---\"\n",
    "\n",
    "# !!! IMPORTANT: Modify this for your specific sample !!!\n",
    "SAMPLEID=\"jetsonhack_ORANGE_run1_20220207\"\n",
    "echo \"SAMPLEID set to: ${SAMPLEID}\"\n",
    "\n",
    "# Dynamically set THREADS based on available processing units\n",
    "if command -v nproc &> /dev/null; then\n",
    "    THREADS=$(nproc)\n",
    "    if ! [[ \"$THREADS\" =~ ^[1-9][0-9]*$ ]]; then # Validate that THREADS is a positive integer\n",
    "        echo \"Warning: nproc returned an invalid value ('${THREADS}'). Defaulting THREADS to 4.\"\n",
    "        THREADS=4\n",
    "    else\n",
    "        echo \"Detected ${THREADS} available processing units.\"\n",
    "    fi\n",
    "else\n",
    "    echo \"Warning: nproc command not found. Defaulting THREADS to 4.\"\n",
    "    THREADS=4\n",
    "fi\n",
    "# Optional: Cap the number of threads to a maximum value if desired\n",
    "# MAX_SCRIPT_THREADS=16 # Example cap\n",
    "# if [ \"$THREADS\" -gt \"$MAX_SCRIPT_THREADS\" ]; then\n",
    "#     echo \"Capping THREADS from ${THREADS} to ${MAX_SCRIPT_THREADS}.\"\n",
    "#     THREADS=$MAX_SCRIPT_THREADS\n",
    "# fi\n",
    "\n",
    "MAXCHAN=256 # Channel threshold for \"AS\" treatment\n",
    "\n",
    "# Input Data Location\n",
    "BUCKET_DIR=\"${HOME}/dsc-nanopore-data/as_data\"\n",
    "\n",
    "# Reference Genome\n",
    "REFERENCE_BASENAME=\"D6322.custom.reference.fasta\"\n",
    "REFERENCE=\"${BUCKET_DIR}/${REFERENCE_BASENAME}\"\n",
    "\n",
    "# Main Output Directory\n",
    "MAIN_OUTPUT_ROOT=\"${HOME}/Output_AS\"\n",
    "OUTPUT_DIR=\"${MAIN_OUTPUT_ROOT}/${SAMPLEID}\"\n",
    "\n",
    "# Organism reference names\n",
    "Bacillus='Bacillus_subtilis_genome'\n",
    "Enterococcus='Enterococcus_faecalis_genome'\n",
    "Escherichia='Escherichia_coli_plasmid Escherichia_coli_chromosome'\n",
    "Listeria='Listeria_monocytogenes_genome'\n",
    "Pseudomonas='Pseudomonas_aeruginosa_genome'\n",
    "Salmonella='Salmonella_enterica_genome'\n",
    "Staphylococcus='Staphylococcus_aureus_chromosome Staphylococcus_aureus_plasmid1 Staphylococcus_aureus_plasmid2 Staphylococcus_aureus_plasmid3'\n",
    "\n",
    "# Lists for looping\n",
    "TRMT_LIST=(\"AS\" \"Control\")\n",
    "ISO_LIST=(\n",
    "    \"Bacillus\" \"Enterococcus\" \"Escherichia\" \"Listeria\"\n",
    "    \"Pseudomonas\" \"Salmonella\" \"Staphylococcus\"\n",
    ")\n",
    "\n",
    "# Derived Paths & Output Subdirectories\n",
    "FASTA_OUT_DIR=\"${OUTPUT_DIR}/fasta\"\n",
    "SUMMARY_DIR=\"${OUTPUT_DIR}/summary_data\"\n",
    "FASTQ_TRMT_DIR=\"${OUTPUT_DIR}/fastq_treatment\"\n",
    "FASTQ_TRMT_MAPPED_DIR=\"${OUTPUT_DIR}/fastq_treatment_mapped\"\n",
    "FASTQ_TRMT_ISO_DIR=\"${OUTPUT_DIR}/fastq_treatment_iso\"\n",
    "MAPPED_DIR=\"${OUTPUT_DIR}/mapped\"\n",
    "CONCAT_READS_PASS=\"${FASTA_OUT_DIR}/${SAMPLEID}.reads.pass.fastq.gz\"\n",
    "BASECALLED_SUMMARY_DIR=\"${BUCKET_DIR}/${SAMPLEID}/basecalled\"\n",
    "BASECALLED_FASTQ_PASS_DIR=\"${BUCKET_DIR}/${SAMPLEID}/basecalled/fastq_pass\"\n",
    "\n",
    "echo \"--- Configuration Display ---\"\n",
    "echo \"SAMPLEID: ${SAMPLEID}\"\n",
    "echo \"THREADS: ${THREADS}\"\n",
    "echo \"MAXCHAN: ${MAXCHAN}\"\n",
    "echo \"BUCKET_DIR (Input Data): ${BUCKET_DIR}\"\n",
    "echo \"REFERENCE: ${REFERENCE}\"\n",
    "echo \"MAIN_OUTPUT_ROOT: ${MAIN_OUTPUT_ROOT}\"\n",
    "echo \"OUTPUT_DIR (Sample Specific): ${OUTPUT_DIR}\"\n",
    "echo \"--- End Configuration Display ---\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a4485-457b-4868-8d2c-d6830bad54d3",
   "metadata": {},
   "source": [
    "### **Peek at the Initial Setup (Optional)**\n",
    "\n",
    "After running the block above, you can check if the main directories are accessible or if the output directory is ready to be created."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6ab6b39-b426-4df2-ae98-5751c5d89fc1",
   "metadata": {},
   "source": [
    "echo \"--- Peeking at Initial Setup ---\"\n",
    "echo \"Listing BUCKET_DIR (input data root):\"\n",
    "ls -ld \"${BUCKET_DIR}\" || echo \"BUCKET_DIR not found or not accessible.\"\n",
    "echo \"Listing MAIN_OUTPUT_ROOT (where sample output will go):\"\n",
    "ls -ld \"${MAIN_OUTPUT_ROOT}\" || echo \"MAIN_OUTPUT_ROOT not found or not accessible. It will be created if it's just ${HOME}/Output_AS.\"\n",
    "echo \"Path for sample-specific output: ${OUTPUT_DIR}\"\n",
    "echo \"--- End Peeking ---\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af690223-30b5-4582-b027-5c6ab0468bad",
   "metadata": {},
   "source": [
    "## **Section 1: Find Sequencing Summary & Determine Column Numbers**\n",
    "\n",
    "This section dynamically locates your sequencing\\_summary\\*.txt file and then reads its header to determine the column numbers for \"channel\", \"passes\\_filtering\", \"sequence\\_length\\_template\", and \"read\\_id\". This makes the script robust to changes in column order."
   ]
  },
  {
   "cell_type": "raw",
   "id": "125d1f8f-3b84-4538-a369-ee6bad389ccf",
   "metadata": {},
   "source": [
    "# --- Dynamically Find Sequencing Summary File ---\n",
    "echo \"--- Finding Sequencing Summary File ---\"\n",
    "FOUND_SUMMARIES=()\n",
    "if [ -d \"${BASECALLED_SUMMARY_DIR}\" ]; then\n",
    "    mapfile -t FOUND_SUMMARIES < <(find \"${BASECALLED_SUMMARY_DIR}\" -maxdepth 1 -name \"sequencing_summary*.txt\" -print)\n",
    "else\n",
    "    echo \"ERROR: Basecalled summary directory not found: ${BASECALLED_SUMMARY_DIR}\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "NUM_FOUND_SUMMARIES=${#FOUND_SUMMARIES[@]}\n",
    "BASECALLED_SEQ_SUMMARY=\"\"\n",
    "\n",
    "if [ \"${NUM_FOUND_SUMMARIES}\" -eq 0 ]; then\n",
    "    echo \"ERROR: No sequencing summary file found in ${BASECALLED_SUMMARY_DIR} matching 'sequencing_summary*.txt'\"\n",
    "    exit 1\n",
    "elif [ \"${NUM_FOUND_SUMMARIES}\" -gt 1 ]; then\n",
    "    echo \"ERROR: Multiple sequencing summary files found in ${BASECALLED_SUMMARY_DIR} matching 'sequencing_summary*.txt'. Please ensure only one exists:\"\n",
    "    printf \"  %s\\n\" \"${FOUND_SUMMARIES[@]}\"\n",
    "    exit 1\n",
    "else\n",
    "    BASECALLED_SEQ_SUMMARY=\"${FOUND_SUMMARIES[0]}\"\n",
    "    echo \"Using sequencing summary file: ${BASECALLED_SEQ_SUMMARY}\"\n",
    "fi\n",
    "echo \"\"\n",
    "\n",
    "# --- Dynamically Determine Column Numbers from Sequencing Summary Header ---\n",
    "echo \"--- Determining Column Numbers from Header ---\"\n",
    "HEADER_LINE=$(head -n1 \"${BASECALLED_SEQ_SUMMARY}\")\n",
    "if [ -z \"${HEADER_LINE}\" ]; then\n",
    "    echo \"ERROR: Sequencing summary file is empty or header could not be read: ${BASECALLED_SEQ_SUMMARY}\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "IFS=$'\\t' read -r -a HEADER_FIELDS <<< \"$HEADER_LINE\"\n",
    "\n",
    "COL_CHANNEL_NUM=-1\n",
    "COL_PASSES_FILTERING_NUM=-1\n",
    "COL_SEQUENCE_LENGTH_TEMPLATE_NUM=-1\n",
    "COL_READ_ID_NUM=-1\n",
    "\n",
    "for i in \"${!HEADER_FIELDS[@]}\"; do\n",
    "    FIELD_NAME=\"${HEADER_FIELDS[$i]}\"\n",
    "    case \"${FIELD_NAME}\" in\n",
    "        \"channel\") COL_CHANNEL_NUM=$((i+1)) ;;\n",
    "        \"passes_filtering\") COL_PASSES_FILTERING_NUM=$((i+1)) ;;\n",
    "        \"sequence_length_template\") COL_SEQUENCE_LENGTH_TEMPLATE_NUM=$((i+1)) ;;\n",
    "        \"read_id\") COL_READ_ID_NUM=$((i+1)) ;;\n",
    "    esac\n",
    "done\n",
    "unset IFS\n",
    "\n",
    "MISSING_HEADERS=0\n",
    "if [ \"$COL_CHANNEL_NUM\" -eq -1 ]; then echo \"ERROR: Header 'channel' not found in ${BASECALLED_SEQ_SUMMARY}\"; MISSING_HEADERS=1; fi\n",
    "if [ \"$COL_PASSES_FILTERING_NUM\" -eq -1 ]; then echo \"ERROR: Header 'passes_filtering' not found in ${BASECALLED_SEQ_SUMMARY}\"; MISSING_HEADERS=1; fi\n",
    "if [ \"$COL_SEQUENCE_LENGTH_TEMPLATE_NUM\" -eq -1 ]; then echo \"ERROR: Header 'sequence_length_template' not found in ${BASECALLED_SEQ_SUMMARY}\"; MISSING_HEADERS=1; fi\n",
    "if [ \"$COL_READ_ID_NUM\" -eq -1 ]; then echo \"ERROR: Header 'read_id' not found in ${BASECALLED_SEQ_SUMMARY}\"; MISSING_HEADERS=1; fi\n",
    "\n",
    "if [ \"$MISSING_HEADERS\" -eq 1 ]; then\n",
    "    echo \"Please check the header names in your sequencing summary file.\"\n",
    "    exit 1\n",
    "fi\n",
    "echo \"Column mapping successful:\"\n",
    "echo \"  Channel column: ${COL_CHANNEL_NUM}\"\n",
    "echo \"  Passes_filtering column: ${COL_PASSES_FILTERING_NUM}\"\n",
    "echo \"  Sequence_length_template column: ${COL_SEQUENCE_LENGTH_TEMPLATE_NUM}\"\n",
    "echo \"  Read_id column: ${COL_READ_ID_NUM}\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5f889-e319-40f2-b564-0d4aab4a3be1",
   "metadata": {},
   "source": [
    "### **Peek at Column Determination (Optional)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca1a389-884c-4640-8f50-e4ab21d9855d",
   "metadata": {},
   "source": [
    "echo \"--- Peeking at Column Determination ---\"\n",
    "echo \"Found sequencing summary file: ${BASECALLED_SEQ_SUMMARY}\"\n",
    "echo \"Header line used for column mapping: \"\n",
    "echo \"${HEADER_LINE}\"\n",
    "echo \"Determined column numbers:\"\n",
    "echo \"  Channel: ${COL_CHANNEL_NUM}\"\n",
    "echo \"  Passes Filtering: ${COL_PASSES_FILTERING_NUM}\"\n",
    "echo \"  Sequence Length: ${COL_SEQUENCE_LENGTH_TEMPLATE_NUM}\"\n",
    "echo \"  Read ID: ${COL_READ_ID_NUM}\"\n",
    "echo \"--- End Peeking ---\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada417e1-fafd-42d1-951a-49158376bff9",
   "metadata": {},
   "source": [
    "## **Section 2: Create Output Directories & Verify Inputs**\n",
    "\n",
    "This block creates the necessary directory structure for all output files and then verifies that essential input files (reference, sequencing summary, FASTQ directory) exist."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e597c195-3378-4750-b58d-7f4c2fd1e578",
   "metadata": {},
   "source": [
    "# --- Create Base Output Directories ---\n",
    "echo \"--- Creating Base Output Directories ---\"\n",
    "mkdir -p \"${OUTPUT_DIR}\"\n",
    "mkdir -p \"${FASTA_OUT_DIR}\"\n",
    "mkdir -p \"${SUMMARY_DIR}\"\n",
    "mkdir -p \"${FASTQ_TRMT_DIR}\"\n",
    "mkdir -p \"${FASTQ_TRMT_MAPPED_DIR}\"\n",
    "mkdir -p \"${FASTQ_TRMT_ISO_DIR}\"\n",
    "mkdir -p \"${MAPPED_DIR}\"\n",
    "echo \"Base output directories ensured.\"\n",
    "echo \"\"\n",
    "\n",
    "# --- Verify Input Files ---\n",
    "echo \"--- Verifying Essential Input Files ---\"\n",
    "if [ ! -f \"${REFERENCE}\" ]; then\n",
    "    echo \"ERROR: Reference file not found at ${REFERENCE}\"\n",
    "    exit 1\n",
    "fi\n",
    "if [ ! -f \"${BASECALLED_SEQ_SUMMARY}\" ]; then\n",
    "    echo \"ERROR: Basecalled sequencing summary was not successfully identified or is not a file: ${BASECALLED_SEQ_SUMMARY}\"\n",
    "    exit 1\n",
    "fi\n",
    "if [ ! -d \"${BASECALLED_FASTQ_PASS_DIR}\" ]; then\n",
    "    echo \"ERROR: Basecalled fastq_pass directory not found at ${BASECALLED_FASTQ_PASS_DIR}\"\n",
    "    exit 1\n",
    "fi\n",
    "echo \"Essential input files verified.\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d56698-5ffd-48e5-bafd-afb40acb6150",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Peek at Created Directories (Optional)**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c23c04c2-815e-4328-a8b7-5675b12f80bc",
   "metadata": {},
   "source": [
    "echo \"--- Peeking at Created Directories ---\"\n",
    "echo \"Listing main output directory contents:\"\n",
    "ls -ld \"${OUTPUT_DIR}\"\n",
    "echo \"Listing subdirectories within ${OUTPUT_DIR}:\"\n",
    "ls -l \"${OUTPUT_DIR}\"\n",
    "echo \"--- End Peeking ---\"\n",
    "echo \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370804f2-31ab-498a-8bdc-7e2b0f0889ed",
   "metadata": {},
   "source": [
    "## **Section 3: Part 1 \\- Splitting Output by Treatment**\n",
    "\n",
    "This part of the pipeline focuses on initial read processing:\n",
    "\n",
    "1. **Concatenate Pass Reads**: All fastq.gz files from the basecalled/fastq\\_pass directory are combined into a single file.  \n",
    "2. **Process Each Treatment**: A loop iterates through \"AS\" and \"Control\" treatments. For each:  \n",
    "   * A filtered sequencing summary is created based on channel, passes\\_filtering status, and sequence length.  \n",
    "   * A list of read IDs matching these criteria is generated.  \n",
    "   * A filtered FASTQ file for the treatment is created using seqtk."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b12ea95-b125-446d-ba0e-570c95ee4fd2",
   "metadata": {},
   "source": [
    "# --- Part 1: Splitting output by Treatment ---\n",
    "echo \"--- Part 1: Splitting Output by Treatment ---\"\n",
    "\n",
    "# Collect all the pass reads into a single container\n",
    "echo \"Concatenating pass reads into: ${CONCAT_READS_PASS}\"\n",
    "if [ -z \"$(ls -A ${BASECALLED_FASTQ_PASS_DIR}/*.fastq.gz 2>/dev/null)\" ]; then\n",
    "   echo \"WARNING: No .fastq.gz files found in ${BASECALLED_FASTQ_PASS_DIR}/\"\n",
    "   echo \"ERROR: No input FASTQ files to process. Exiting.\"\n",
    "   exit 1\n",
    "else\n",
    "   cat \"${BASECALLED_FASTQ_PASS_DIR}/\"*.fastq.gz > \"${CONCAT_READS_PASS}\"\n",
    "   echo \"Successfully concatenated reads to ${CONCAT_READS_PASS}\"\n",
    "fi\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f465282-e5fe-4274-8677-a6f492dd0cb1",
   "metadata": {},
   "source": [
    "### **Peek at Concatenated Reads**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf2e5861-139f-49b0-9c5f-a739a603e923",
   "metadata": {},
   "source": [
    "echo \"--- Peeking at Concatenated Reads ---\"\n",
    "echo \"Details of the concatenated reads file:\"\n",
    "ls -lh \"${CONCAT_READS_PASS}\"\n",
    "echo \"First read (4 lines) from the concatenated file:\"\n",
    "zcat \"${CONCAT_READS_PASS}\" | head -n 4\n",
    "echo \"Total number of lines (divisible by 4 for FASTQ records):\"\n",
    "zcat \"${CONCAT_READS_PASS}\" | wc -l\n",
    "echo \"--- End Peeking ---\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ff6bf-7b1e-4da3-b921-753be67ac74f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, continue with the loop for processing each treatment."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4db826e1-f6fa-4a97-a2e1-e3d7a5c61530",
   "metadata": {},
   "source": [
    "# Process each treatment (AS, Control)\n",
    "for TRMT in \"${TRMT_LIST[@]}\"; do\n",
    "    echo \"Processing Treatment: ${TRMT}\"\n",
    "\n",
    "    TRMT_SEQSUM_OUT=\"${FASTA_OUT_DIR}/${SAMPLEID}.reads.${TRMT}.seqsum.txt\"\n",
    "    TRMT_FASTQ_OUT=\"${FASTQ_TRMT_DIR}/${TRMT}/${SAMPLEID}.reads.${TRMT}.fastq.gz\"\n",
    "    TRMT_LST_OUT=\"${FASTA_OUT_DIR}/${SAMPLEID}.reads.${TRMT}.lst\"\n",
    "\n",
    "    mkdir -p \"${FASTQ_TRMT_DIR}/${TRMT}\"\n",
    "\n",
    "    echo \"  Output sequencing summary: ${TRMT_SEQSUM_OUT}\"\n",
    "    echo \"  Output FASTQ (gzipped): ${TRMT_FASTQ_OUT}\"\n",
    "    echo \"  Output read list: ${TRMT_LST_OUT}\"\n",
    "\n",
    "    head -n1 \"${BASECALLED_SEQ_SUMMARY}\" > \"${TRMT_SEQSUM_OUT}\"\n",
    "\n",
    "    AWK_CONDITIONAL_LOGIC=\"\"\n",
    "    if [ \"${TRMT}\" == \"AS\" ]; then\n",
    "        AWK_CONDITIONAL_LOGIC='$'${COL_CHANNEL_NUM}' <= '\"${MAXCHAN}\"' && $'${COL_PASSES_FILTERING_NUM}' == \"TRUE\" && $'${COL_SEQUENCE_LENGTH_TEMPLATE_NUM}' >= 1000'\n",
    "    elif [ \"${TRMT}\" == \"Control\" ]; then\n",
    "        AWK_CONDITIONAL_LOGIC='$'${COL_CHANNEL_NUM}' > '\"${MAXCHAN}\"' && $'${COL_PASSES_FILTERING_NUM}' == \"TRUE\" && $'${COL_SEQUENCE_LENGTH_TEMPLATE_NUM}' >= 1000'\n",
    "    else\n",
    "        echo \"ERROR: Unknown TRMT value: ${TRMT}\"\n",
    "        exit 1\n",
    "    fi\n",
    "\n",
    "    AWK_SCRIPT_FOR_SUM=\"${AWK_CONDITIONAL_LOGIC} {print}\"\n",
    "    echo \"  Filtering sequencing summary and appending to ${TRMT_SEQSUM_OUT}\"\n",
    "    awk -F'\\t' -v OFS='\\t' \"${AWK_SCRIPT_FOR_SUM}\" \"${BASECALLED_SEQ_SUMMARY}\" >> \"${TRMT_SEQSUM_OUT}\"\n",
    "\n",
    "    AWK_SCRIPT_FOR_LST=\"${AWK_CONDITIONAL_LOGIC} {print \\$${COL_READ_ID_NUM}}\"\n",
    "    echo \"  Generating read ID list: ${TRMT_LST_OUT}\"\n",
    "    awk -F'\\t' \"${AWK_SCRIPT_FOR_LST}\" \"${BASECALLED_SEQ_SUMMARY}\" > \"${TRMT_LST_OUT}\"\n",
    "\n",
    "    echo \"  Generating FASTQ and gzipping: ${TRMT_FASTQ_OUT}\"\n",
    "    if [ -s \"${CONCAT_READS_PASS}\" ] && [ -s \"${TRMT_LST_OUT}\" ]; then\n",
    "        # Using pigz if available, otherwise gzip\n",
    "        if command -v pigz &> /dev/null; then\n",
    "            seqtk subseq \"${CONCAT_READS_PASS}\" \"${TRMT_LST_OUT}\" | pigz -c -p \"${THREADS}\" > \"${TRMT_FASTQ_OUT}\"\n",
    "        else\n",
    "            echo \"  pigz not found, using gzip (single-threaded for compression).\"\n",
    "            seqtk subseq \"${CONCAT_READS_PASS}\" \"${TRMT_LST_OUT}\" | gzip -c > \"${TRMT_FASTQ_OUT}\"\n",
    "        fi\n",
    "        echo \"  FASTQ for ${TRMT} generated and gzipped.\"\n",
    "    else\n",
    "        echo \"  WARNING: Either ${CONCAT_READS_PASS} does not exist/is empty or ${TRMT_LST_OUT} is empty. Skipping FASTQ generation for ${TRMT}.\"\n",
    "        if command -v pigz &> /dev/null; then\n",
    "            pigz -c -p \"${THREADS}\" < /dev/null > \"${TRMT_FASTQ_OUT}\"\n",
    "        else\n",
    "            gzip -c < /dev/null > \"${TRMT_FASTQ_OUT}\"\n",
    "        fi\n",
    "        echo \"  Created empty ${TRMT_FASTQ_OUT}.\"\n",
    "    fi\n",
    "    echo \"\"\n",
    "\n",
    "    # Peek at outputs for THIS treatment iteration\n",
    "    echo \"  --- Peeking at outputs for Treatment: ${TRMT} ---\"\n",
    "    echo \"  Details of sequencing summary (${TRMT_SEQSUM_OUT}):\"\n",
    "    ls -lh \"${TRMT_SEQSUM_OUT}\"; head -n 3 \"${TRMT_SEQSUM_OUT}\"; echo \"  Total lines: $(wc -l < \"${TRMT_SEQSUM_OUT}\")\"\n",
    "    echo \"  Details of read ID list (${TRMT_LST_OUT}):\"\n",
    "    ls -lh \"${TRMT_LST_OUT}\"; head -n 3 \"${TRMT_LST_OUT}\"; echo \"  Total read IDs: $(wc -l < \"${TRMT_LST_OUT}\")\"\n",
    "    echo \"  Details of filtered FASTQ (${TRMT_FASTQ_OUT}):\"\n",
    "    ls -lh \"${TRMT_FASTQ_OUT}\"\n",
    "    echo \"  First two reads from filtered FASTQ:\"\n",
    "    zcat \"${TRMT_FASTQ_OUT}\" | head -n 8\n",
    "    echo \"  --- End Peeking for ${TRMT} ---\"\n",
    "    echo \"\"\n",
    "\n",
    "done\n",
    "echo \"--- End of Part 1 ---\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcadf4c-bb5e-43ed-95ee-2531fd1a322e",
   "metadata": {},
   "source": [
    "## **Section 4: Part 1b \\- Combine Treatment-Specific Sequencing Summaries**\n",
    "\n",
    "After creating individual sequencing summaries for each treatment, this step combines them into a single file, adding a new \"TRMT\" column to indicate the origin of each row."
   ]
  },
  {
   "cell_type": "raw",
   "id": "99a82f21-30d1-4cf8-a61b-bdb8cd30000b",
   "metadata": {},
   "source": [
    "# --- Part 1b: Combine Treatment-Specific Sequencing Summaries ---\n",
    "echo \"--- Part 1b: Combining Treatment-Specific Sequencing Summaries ---\"\n",
    "COMBINED_READS_TRMT_SEQSUM_FILE=\"${SUMMARY_DIR}/${SAMPLEID}.reads.all_trmts.combined.seqsum.txt\"\n",
    "HEADER_WRITTEN_TRMT_COMBINE=false\n",
    "\n",
    "echo \"Output will be: ${COMBINED_READS_TRMT_SEQSUM_FILE}\"\n",
    "\n",
    "for TRMT in \"${TRMT_LIST[@]}\"; do\n",
    "    INPUT_TRMT_SEQSUM_FILE=\"${FASTA_OUT_DIR}/${SAMPLEID}.reads.${TRMT}.seqsum.txt\"\n",
    "    echo \"Processing for combination: ${INPUT_TRMT_SEQSUM_FILE}\"\n",
    "\n",
    "    if [ ! -f \"${INPUT_TRMT_SEQSUM_FILE}\" ]; then\n",
    "        echo \"  --> Warning: Input file for TRMT combine not found, skipping: ${INPUT_TRMT_SEQSUM_FILE}\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    if [ \"${HEADER_WRITTEN_TRMT_COMBINE}\" = false ]; then\n",
    "        awk -v trmt_val=\"$TRMT\" 'BEGIN{OFS=\"\\t\"} FNR==1 {print \"TRMT\", $0} FNR>1 {print trmt_val, $0}' \\\n",
    "            \"${INPUT_TRMT_SEQSUM_FILE}\" > \"${COMBINED_READS_TRMT_SEQSUM_FILE}\"\n",
    "        HEADER_WRITTEN_TRMT_COMBINE=true\n",
    "        echo \"  --> Header written and first TRMT seqsum processed.\"\n",
    "    else\n",
    "        awk -v trmt_val=\"$TRMT\" 'BEGIN{OFS=\"\\t\"} FNR>1 {print trmt_val, $0}' \\\n",
    "            \"${INPUT_TRMT_SEQSUM_FILE}\" >> \"${COMBINED_READS_TRMT_SEQSUM_FILE}\"\n",
    "        echo \"  --> Appended TRMT seqsum to combined file.\"\n",
    "    fi\n",
    "done\n",
    "echo \"Treatment-specific sequencing summaries combined.\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53db9ce-845d-4280-82a8-211125b47b6b",
   "metadata": {},
   "source": [
    "### **Peek at Combined Treatment Summary**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6145ca2-d654-4c02-ac09-e4a1e8374694",
   "metadata": {},
   "source": [
    "echo \"--- Peeking at Combined Treatment Sequencing Summary ---\"\n",
    "echo \"Details of the combined file (${COMBINED_READS_TRMT_SEQSUM_FILE}):\"\n",
    "ls -lh \"${COMBINED_READS_TRMT_SEQSUM_FILE}\"\n",
    "echo \"First 5 lines of the combined file:\"\n",
    "head -n 5 \"${COMBINED_READS_TRMT_SEQSUM_FILE}\"\n",
    "echo \"Total lines in combined file: $(wc -l < \"${COMBINED_READS_TRMT_SEQSUM_FILE}\")\"\n",
    "echo \"--- End Peeking ---\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df99d4-5443-455b-88e5-0a8960ab7acc",
   "metadata": {},
   "source": [
    "## **Section 5: Part 2 \\- Analyzing the Output (Mapping & Isolate Processing)**\n",
    "\n",
    "This is the main analysis part. It loops through each treatment (\"AS\", \"Control\"). For each treatment:\n",
    "\n",
    "1. **Map to Entire Community**: Reads are mapped to the full reference genome using minimap2. The resulting BAM file is sorted and indexed.  \n",
    "2. **Extract All Mapped Reads**: A list of all read IDs that mapped to any part of the reference is created. A FASTQ file containing these mapped reads is generated, along with a corresponding sequencing summary.  \n",
    "3. **Process Individual Isolates**: An inner loop iterates through each defined isolate (Bacillus, E. coli, etc.).  \n",
    "   * The community BAM file is filtered to get reads mapping specifically to the current isolate's reference sequence(s).  \n",
    "   * This isolate-specific BAM is indexed.  \n",
    "   * A list of read IDs mapped to this isolate is generated.  \n",
    "   * A FASTQ file and sequencing summary for these isolate-specific reads are created.\n",
    "\n",
    "**Note**: This is a large block as it contains nested loops. It's designed to be run as one unit."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0af0744c-0708-4e57-8bbc-baa9da93dddc",
   "metadata": {},
   "source": [
    "# --- Part 2: Analyzing the output (Mapping and Further Processing) ---\n",
    "echo \"--- Part 2: Analyzing the Output ---\"\n",
    "\n",
    "# Loop through treatment conditions for mapping\n",
    "for TRMT in \"${TRMT_LIST[@]}\"; do\n",
    "    echo \"\"\n",
    "    echo \"--- Analyzing Treatment for Mapping: ${TRMT} ---\"\n",
    "\n",
    "    TRMT_FASTQ_INPUT=\"${FASTQ_TRMT_DIR}/${TRMT}/${SAMPLEID}.reads.${TRMT}.fastq.gz\"\n",
    "\n",
    "    if [ ! -s \"${TRMT_FASTQ_INPUT}\" ]; then\n",
    "        echo \"  WARNING: Input FASTQ for mapping not found or empty: ${TRMT_FASTQ_INPUT}. Skipping mapping for ${TRMT}.\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    ANALYSIS_ALL_FASTQ_OUT=\"${FASTQ_TRMT_MAPPED_DIR}/${TRMT}/${SAMPLEID}.mapped.${TRMT}.ALL.fastq.gz\"\n",
    "    ANALYSIS_ALL_BAM_OUT=\"${MAPPED_DIR}/${SAMPLEID}.${TRMT}.ALL.bam\"\n",
    "    ANALYSIS_ALL_LIST_OUT=\"${MAPPED_DIR}/${SAMPLEID}.${TRMT}.ALL.lst\"\n",
    "    ANALYSIS_ALL_SEQSUM_OUT=\"${FASTA_OUT_DIR}/${SAMPLEID}.mapped.${TRMT}.ALL.seqsum.txt\"\n",
    "\n",
    "    mkdir -p \"${FASTQ_TRMT_MAPPED_DIR}/${TRMT}\"\n",
    "\n",
    "    echo \"  Input FASTQ for mapping: ${TRMT_FASTQ_INPUT}\"\n",
    "    echo \"  Output Mapped FASTQ (ALL, gzipped): ${ANALYSIS_ALL_FASTQ_OUT}\"\n",
    "    echo \"  Output BAM (ALL mapped): ${ANALYSIS_ALL_BAM_OUT}\"\n",
    "\n",
    "    SAMTOOLS_SORT_TEMP=\"${MAPPED_DIR}/${SAMPLEID}.${TRMT}.reads.tmp\"\n",
    "    echo \"  Mapping reads to entire community...\"\n",
    "    minimap2 -ax map-ont -t \"${THREADS}\" \"${REFERENCE}\" \"${TRMT_FASTQ_INPUT}\" | \\\n",
    "        samtools sort -@ \"${THREADS}\" -T \"${SAMTOOLS_SORT_TEMP}\" -o - | \\\n",
    "        samtools view -F 2308 -b -o \"${ANALYSIS_ALL_BAM_OUT}\" -\n",
    "    echo \"  Reads mapped to ${ANALYSIS_ALL_BAM_OUT}.\"\n",
    "\n",
    "    # Peek at the \"ALL\" BAM file\n",
    "    echo \"    --- Peeking at ALL Community BAM for ${TRMT} ---\"\n",
    "    echo \"    Details of BAM file (${ANALYSIS_ALL_BAM_OUT}):\"\n",
    "    ls -lh \"${ANALYSIS_ALL_BAM_OUT}\"\n",
    "    echo \"    Samtools flagstat summary:\"\n",
    "    samtools flagstat \"${ANALYSIS_ALL_BAM_OUT}\"\n",
    "    echo \"    First 2 alignment lines (header might be long):\"\n",
    "    samtools view \"${ANALYSIS_ALL_BAM_OUT}\" | head -n 2\n",
    "    echo \"    --- End Peeking ---\"\n",
    "\n",
    "    echo \"  Indexing BAM file: ${ANALYSIS_ALL_BAM_OUT}\"\n",
    "    samtools index -@ \"${THREADS}\" \"${ANALYSIS_ALL_BAM_OUT}\"\n",
    "\n",
    "    echo \"  Extracting list of all mapped read IDs: ${ANALYSIS_ALL_LIST_OUT}\"\n",
    "    samtools view \"${ANALYSIS_ALL_BAM_OUT}\" | cut -f1 | sort -u > \"${ANALYSIS_ALL_LIST_OUT}\"\n",
    "    \n",
    "    # Peek at the \"ALL\" mapped read list\n",
    "    echo \"    --- Peeking at ALL Mapped Read List for ${TRMT} ---\"\n",
    "    echo \"    Details of read list (${ANALYSIS_ALL_LIST_OUT}):\"\n",
    "    ls -lh \"${ANALYSIS_ALL_LIST_OUT}\"; head -n 3 \"${ANALYSIS_ALL_LIST_OUT}\"; echo \"    Total mapped read IDs: $(wc -l < \"${ANALYSIS_ALL_LIST_OUT}\")\"\n",
    "    echo \"    --- End Peeking ---\"\n",
    "\n",
    "    echo \"  Generating FASTQ of all mapped reads: ${ANALYSIS_ALL_FASTQ_OUT}\"\n",
    "    if [ -s \"${ANALYSIS_ALL_LIST_OUT}\" ]; then\n",
    "        if command -v pigz &> /dev/null; then\n",
    "            seqtk subseq \"${TRMT_FASTQ_INPUT}\" \"${ANALYSIS_ALL_LIST_OUT}\" | pigz -c -p \"${THREADS}\" > \"${ANALYSIS_ALL_FASTQ_OUT}\"\n",
    "        else\n",
    "            seqtk subseq \"${TRMT_FASTQ_INPUT}\" \"${ANALYSIS_ALL_LIST_OUT}\" | gzip -c > \"${ANALYSIS_ALL_FASTQ_OUT}\"\n",
    "        fi\n",
    "        echo \"  FASTQ of all mapped reads generated.\"\n",
    "    else\n",
    "        echo \"  WARNING: No reads mapped for ${TRMT} (list is empty). Skipping FASTQ generation for ALL mapped.\"\n",
    "        if command -v pigz &> /dev/null; then\n",
    "            pigz -c -p \"${THREADS}\" < /dev/null > \"${ANALYSIS_ALL_FASTQ_OUT}\"\n",
    "        else\n",
    "            gzip -c < /dev/null > \"${ANALYSIS_ALL_FASTQ_OUT}\"\n",
    "        fi\n",
    "        echo \"  Created empty ${ANALYSIS_ALL_FASTQ_OUT}.\"\n",
    "    fi\n",
    "\n",
    "    # Peek at the \"ALL\" mapped FASTQ\n",
    "    echo \"    --- Peeking at ALL Mapped FASTQ for ${TRMT} ---\"\n",
    "    echo \"    Details of FASTQ file (${ANALYSIS_ALL_FASTQ_OUT}):\"\n",
    "    ls -lh \"${ANALYSIS_ALL_FASTQ_OUT}\"\n",
    "    echo \"    First two reads (8 lines) from mapped FASTQ:\"\n",
    "    zcat \"${ANALYSIS_ALL_FASTQ_OUT}\" | head -n 8\n",
    "    echo \"    --- End Peeking ---\"\n",
    "\n",
    "    echo \"  Generating sequencing summary for all mapped reads: ${ANALYSIS_ALL_SEQSUM_OUT}\"\n",
    "    head -n1 \"${BASECALLED_SEQ_SUMMARY}\" > \"${ANALYSIS_ALL_SEQSUM_OUT}\"\n",
    "    if [ -s \"${ANALYSIS_ALL_LIST_OUT}\" ]; then\n",
    "        grep -F -f \"${ANALYSIS_ALL_LIST_OUT}\" \"${BASECALLED_SEQ_SUMMARY}\" >> \"${ANALYSIS_ALL_SEQSUM_OUT}\"\n",
    "        echo \"  Sequencing summary for all mapped reads generated.\"\n",
    "    else\n",
    "        echo \"  WARNING: No reads mapped for ${TRMT}. Mapped sequencing summary will only contain header.\"\n",
    "    fi\n",
    "    \n",
    "    # Peek at the \"ALL\" mapped sequencing summary\n",
    "    echo \"    --- Peeking at ALL Mapped Sequencing Summary for ${TRMT} ---\"\n",
    "    echo \"    Details of seqsum file (${ANALYSIS_ALL_SEQSUM_OUT}):\"\n",
    "    ls -lh \"${ANALYSIS_ALL_SEQSUM_OUT}\"; head -n 3 \"${ANALYSIS_ALL_SEQSUM_OUT}\"; echo \"    Total lines: $(wc -l < \"${ANALYSIS_ALL_SEQSUM_OUT}\")\"\n",
    "    echo \"    --- End Peeking ---\"\n",
    "    echo \"\"\n",
    "\n",
    "    echo \"  --- Processing individual organisms for Treatment: ${TRMT} ---\"\n",
    "    for ISO in \"${ISO_LIST[@]}\"; do\n",
    "        CURRENT_ISO_REF_NAME=\"${!ISO}\"\n",
    "        echo \"    Processing Isolate: ${ISO} (Reference target(s): ${CURRENT_ISO_REF_NAME})\"\n",
    "\n",
    "        ANALYSIS_ISO_BAM_OUT=\"${MAPPED_DIR}/${SAMPLEID}.${TRMT}.${ISO}.bam\"\n",
    "        ANALYSIS_ISO_LIST_OUT=\"${MAPPED_DIR}/${SAMPLEID}.${TRMT}.${ISO}.lst\"\n",
    "        ANALYSIS_ISO_FASTQ_OUT=\"${FASTQ_TRMT_ISO_DIR}/${TRMT}_${ISO}/${SAMPLEID}.mapped.${TRMT}.${ISO}.fastq.gz\"\n",
    "        ANALYSIS_ISO_SEQSUM_OUT=\"${FASTA_OUT_DIR}/${SAMPLEID}.mapped.${TRMT}.${ISO}.seqsum.txt\"\n",
    "\n",
    "        mkdir -p \"${FASTQ_TRMT_ISO_DIR}/${TRMT}_${ISO}\"\n",
    "\n",
    "        echo \"      Output BAM (${ISO}): ${ANALYSIS_ISO_BAM_OUT}\"\n",
    "        echo \"      Output FASTQ (${ISO}, gzipped): ${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "\n",
    "        if [ ! -s \"${ANALYSIS_ALL_BAM_OUT}\" ]; then\n",
    "            echo \"      WARNING: Parent BAM ${ANALYSIS_ALL_BAM_OUT} is empty or missing. Skipping isolate ${ISO}.\"\n",
    "            samtools view -b -o \"${ANALYSIS_ISO_BAM_OUT}\" /dev/null\n",
    "            touch \"${ANALYSIS_ISO_LIST_OUT}\"\n",
    "            if command -v pigz &> /dev/null; then\n",
    "                pigz -c -p \"${THREADS}\" < /dev/null > \"${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "            else\n",
    "                gzip -c < /dev/null > \"${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "            fi\n",
    "            head -n1 \"${BASECALLED_SEQ_SUMMARY}\" > \"${ANALYSIS_ISO_SEQSUM_OUT}\"\n",
    "            continue\n",
    "        fi\n",
    "        \n",
    "        echo \"      Filtering BAM for ${ISO}...\"\n",
    "        samtools view -@ \"${THREADS}\" -b \"${ANALYSIS_ALL_BAM_OUT}\" ${CURRENT_ISO_REF_NAME} -o \"${ANALYSIS_ISO_BAM_OUT}\"\n",
    "        echo \"      BAM filtered for ${ISO}.\"\n",
    "        \n",
    "        # Peek at Isolate BAM\n",
    "        echo \"        --- Peeking at Isolate BAM for ${TRMT}-${ISO} ---\"\n",
    "        echo \"        Details of BAM file (${ANALYSIS_ISO_BAM_OUT}):\"\n",
    "        ls -lh \"${ANALYSIS_ISO_BAM_OUT}\"\n",
    "        echo \"        Samtools flagstat summary:\"\n",
    "        samtools flagstat \"${ANALYSIS_ISO_BAM_OUT}\"\n",
    "        echo \"        --- End Peeking ---\"\n",
    "\n",
    "        echo \"      Indexing BAM file for ${ISO}: ${ANALYSIS_ISO_BAM_OUT}\"\n",
    "        samtools index -@ \"${THREADS}\" \"${ANALYSIS_ISO_BAM_OUT}\"\n",
    "\n",
    "        echo \"      Extracting read ID list for ${ISO}: ${ANALYSIS_ISO_LIST_OUT}\"\n",
    "        samtools view -F 0x04 \"${ANALYSIS_ISO_BAM_OUT}\" | cut -f1 | sort -u > \"${ANALYSIS_ISO_LIST_OUT}\"\n",
    "        \n",
    "        # Peek at Isolate read list\n",
    "        echo \"        --- Peeking at Isolate Read List for ${TRMT}-${ISO} ---\"\n",
    "        echo \"        Details of read list (${ANALYSIS_ISO_LIST_OUT}):\"\n",
    "        ls -lh \"${ANALYSIS_ISO_LIST_OUT}\"; head -n 3 \"${ANALYSIS_ISO_LIST_OUT}\"; echo \"        Total read IDs for isolate: $(wc -l < \"${ANALYSIS_ISO_LIST_OUT}\")\"\n",
    "        echo \"        --- End Peeking ---\"\n",
    "\n",
    "        echo \"      Generating FASTQ for ${ISO}: ${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "        if [ -s \"${ANALYSIS_ALL_FASTQ_OUT}\" ] && [ -s \"${ANALYSIS_ISO_LIST_OUT}\" ]; then\n",
    "            if command -v pigz &> /dev/null; then\n",
    "                seqtk subseq \"${ANALYSIS_ALL_FASTQ_OUT}\" \"${ANALYSIS_ISO_LIST_OUT}\" | pigz -c -p \"${THREADS}\" > \"${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "            else\n",
    "                seqtk subseq \"${ANALYSIS_ALL_FASTQ_OUT}\" \"${ANALYSIS_ISO_LIST_OUT}\" | gzip -c > \"${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "            fi\n",
    "            echo \"      FASTQ for ${ISO} generated.\"\n",
    "        else\n",
    "            echo \"      WARNING: Input FASTQ (${ANALYSIS_ALL_FASTQ_OUT}) or list (${ANALYSIS_ISO_LIST_OUT}) is empty/missing. Skipping FASTQ generation for ${ISO}.\"\n",
    "            if command -v pigz &> /dev/null; then\n",
    "                pigz -c -p \"${THREADS}\" < /dev/null > \"${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "            else\n",
    "                gzip -c < /dev/null > \"${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "            fi\n",
    "            echo \"      Created empty ${ANALYSIS_ISO_FASTQ_OUT}.\"\n",
    "        fi\n",
    "\n",
    "        # Peek at Isolate FASTQ\n",
    "        echo \"        --- Peeking at Isolate FASTQ for ${TRMT}-${ISO} ---\"\n",
    "        echo \"        Details of FASTQ file (${ANALYSIS_ISO_FASTQ_OUT}):\"\n",
    "        ls -lh \"${ANALYSIS_ISO_FASTQ_OUT}\"\n",
    "        echo \"        First read (4 lines) from isolate FASTQ:\"\n",
    "        zcat \"${ANALYSIS_ISO_FASTQ_OUT}\" | head -n 4\n",
    "        echo \"        --- End Peeking ---\"\n",
    "        \n",
    "        echo \"      Generating sequencing summary for ${ISO}: ${ANALYSIS_ISO_SEQSUM_OUT}\"\n",
    "        head -n1 \"${BASECALLED_SEQ_SUMMARY}\" > \"${ANALYSIS_ISO_SEQSUM_OUT}\"\n",
    "        if [ -s \"${ANALYSIS_ISO_LIST_OUT}\" ]; then\n",
    "             grep -F -f \"${ANALYSIS_ISO_LIST_OUT}\" \"${BASECALLED_SEQ_SUMMARY}\" >> \"${ANALYSIS_ISO_SEQSUM_OUT}\"\n",
    "             echo \"      Sequencing summary for ${ISO} generated.\"\n",
    "        else\n",
    "            echo \"      WARNING: Read list for ${ISO} is empty. Seqsum for ${ISO} will only contain header.\"\n",
    "        fi\n",
    "        \n",
    "        # Peek at Isolate sequencing summary\n",
    "        echo \"        --- Peeking at Isolate Sequencing Summary for ${TRMT}-${ISO} ---\"\n",
    "        echo \"        Details of seqsum file (${ANALYSIS_ISO_SEQSUM_OUT}):\"\n",
    "        ls -lh \"${ANALYSIS_ISO_SEQSUM_OUT}\"; head -n 3 \"${ANALYSIS_ISO_SEQSUM_OUT}\"; echo \"        Total lines: $(wc -l < \"${ANALYSIS_ISO_SEQSUM_OUT}\")\"\n",
    "        echo \"        --- End Peeking ---\"\n",
    "        echo \"\"\n",
    "    done\n",
    "    echo \"\"\n",
    "done\n",
    "echo \"--- End of Part 2 ---\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ec299-866c-4142-a0c4-2c6ce27b8039",
   "metadata": {},
   "source": [
    "## **Section 6: Part 3 \\- Combine Mapped Isolate-Specific Sequencing Summaries**\n",
    "\n",
    "Finally, this section takes all the individual sequencing summaries created for each isolate within each treatment (`.mapped.${TRMT}.${ISO}.seqsum.txt`) and combines them into one large summary file. It adds two new columns, \"TRMT\" and \"ISO\", to indicate the source of each row."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e69f4f9d-b591-470b-9468-3e891d0503a5",
   "metadata": {},
   "source": [
    "# --- Part 3: Combine Mapped Isolate-Specific Sequencing Summaries ---\n",
    "echo \"--- Part 3: Combining Mapped Isolate-Specific Sequencing Summaries ---\"\n",
    "COMBINED_MAPPED_ISO_SEQSUM_FILE=\"${SUMMARY_DIR}/${SAMPLEID}.mapped.all_trmts.all_isos.combined.seqsum.txt\"\n",
    "HEADER_WRITTEN_ISO_COMBINE=false\n",
    "\n",
    "echo \"Output will be: ${COMBINED_MAPPED_ISO_SEQSUM_FILE}\"\n",
    "\n",
    "for TRMT in \"${TRMT_LIST[@]}\"; do\n",
    "    for ISO in \"${ISO_LIST[@]}\"; do\n",
    "        INPUT_ISO_SEQSUM_FILE=\"${FASTA_OUT_DIR}/${SAMPLEID}.mapped.${TRMT}.${ISO}.seqsum.txt\"\n",
    "        echo \"Processing for combination: ${INPUT_ISO_SEQSUM_FILE}\"\n",
    "\n",
    "        if [ ! -f \"${INPUT_ISO_SEQSUM_FILE}\" ]; then\n",
    "            echo \"  --> Warning: Input file for ISO combine not found, skipping: ${INPUT_ISO_SEQSUM_FILE}\"\n",
    "            continue\n",
    "        fi\n",
    "\n",
    "        if [ \"${HEADER_WRITTEN_ISO_COMBINE}\" = false ]; then\n",
    "            awk -v trmt_val=\"$TRMT\" -v iso_val=\"$ISO\" 'BEGIN{OFS=\"\\t\"} FNR==1 {print \"TRMT\", \"ISO\", $0} FNR>1 {print trmt_val, iso_val, $0}' \\\n",
    "                \"${INPUT_ISO_SEQSUM_FILE}\" > \"${COMBINED_MAPPED_ISO_SEQSUM_FILE}\"\n",
    "            HEADER_WRITTEN_ISO_COMBINE=true\n",
    "            echo \"  --> Header written and first ISO seqsum processed.\"\n",
    "        else\n",
    "            awk -v trmt_val=\"$TRMT\" -v iso_val=\"$ISO\" 'BEGIN{OFS=\"\\t\"} FNR>1 {print trmt_val, iso_val, $0}' \\\n",
    "                \"${INPUT_ISO_SEQSUM_FILE}\" >> \"${COMBINED_MAPPED_ISO_SEQSUM_FILE}\"\n",
    "            echo \"  --> Appended ISO seqsum to combined file.\"\n",
    "        fi\n",
    "    done\n",
    "done\n",
    "echo \"Mapped isolate-specific sequencing summaries combined.\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4c7df-c98d-4a31-9e7e-4cab91b4fc16",
   "metadata": {},
   "source": [
    "### **Peek at Final Combined Mapped Isolate Summary**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "734e5988-7def-4be4-a0a7-bd324e120538",
   "metadata": {},
   "source": [
    "echo \"--- Peeking at Final Combined Mapped Isolate Sequencing Summary ---\"\n",
    "echo \"Details of the final combined file (${COMBINED_MAPPED_ISO_SEQSUM_FILE}):\"\n",
    "ls -lh \"${COMBINED_MAPPED_ISO_SEQSUM_FILE}\"\n",
    "echo \"First 10 lines of the final combined file:\"\n",
    "head -n 10 \"${COMBINED_MAPPED_ISO_SEQSUM_FILE}\"\n",
    "echo \"Total lines in final combined file: $(wc -l < \"${COMBINED_MAPPED_ISO_SEQSUM_FILE}\")\"\n",
    "echo \"--- End Peeking ---\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"--- Adaptive Sampling Analysis Script Finished ---\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
